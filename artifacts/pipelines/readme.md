* _50_ calls > _pipeline_ calls > _load_. The first 2 have foreach loops for iterations and parrallel batches. Allowing to ingest ~2B rows/hr, +24M rows/minute to hit +20TBs in few hours. If copy activities fail due to aka.ms/adflimits and you need to ingest many batches in a short period of time for higher throughput these can be executed from PaaS (ADF, Synapse pipelines). ie. more worksapces, additional parrallel/simultanious batches can ingest to KQL DB - exceeding wks limits. 
* _Transcript_ is stream simulation, _TranscriptRandom_ is hist load using 1 of 3 relative url(s) at random.
